{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "group4_proj_code.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "B1ivHIHnaJZ6"
      },
      "source": [
        "# install pyspark\n",
        "%%bash\n",
        "pip install pyspark"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZiNVFPVjjNhq"
      },
      "source": [
        "# all needed imports\n",
        "import os\n",
        "from pyspark.sql import SparkSession, SQLContext, types, functions as fn, Row\n",
        "from pyspark.sql.functions import substring, regexp_extract, concat, count, avg, when, col, lower, concat_ws \n",
        "from pyspark.ml import feature, regression, evaluation, Pipeline, clustering\n",
        "from pyspark.ml.classification import RandomForestClassifier, LogisticRegression, DecisionTreeClassifier, GBTClassifier\n",
        "\n",
        "from pyspark.ml.clustering import KMeans\n",
        "from pyspark.ml.tuning import ParamGridBuilder,CrossValidator\n",
        "from pyspark.ml.evaluation import MulticlassClassificationEvaluator as mce, ClusteringEvaluator, BinaryClassificationEvaluator as bce\n",
        "from pyspark.ml.feature import RegexTokenizer, StopWordsRemover, CountVectorizer, IDF, VectorAssembler, StandardScaler, PCA, ChiSqSelector, StringIndexer, OneHotEncoder\n",
        "from matplotlib import pyplot as plt\n",
        "from google.colab import files\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import requests\n",
        "\n",
        "spark = SparkSession \\\n",
        "  .builder \\\n",
        "  .master(\"local[*]\")\\\n",
        "  .config(\"spark.memory.fraction\", 0.8) \\\n",
        "  .config(\"spark.executor.memory\", \"12g\") \\\n",
        "  .config(\"spark.driver.memory\", \"12g\")\\\n",
        "  .config(\"spark.memory.offHeap.enabled\",'true')\\\n",
        "  .config(\"spark.memory.offHeap.size\",\"12g\")\\\n",
        "  .getOrCreate()\n",
        "sc = spark.sparkContext\n",
        "sqlContext = SQLContext(sc)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iB9dJrehjhLt"
      },
      "source": [
        "# import raw data\n",
        "raw_data = '/content/gdrive/My Drive/ist718_data/data_group4/renttherunway_final_data.json'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iHFU9ZkHHsac"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "\n",
        "# You must use the definitions above to load your data.\n",
        "data_df=sqlContext.read.json(raw_data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z4PmZhXDkPN7"
      },
      "source": [
        "# Part 1: Data Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OOGRacwHfkrl"
      },
      "source": [
        "# reformat weight and height \n",
        "data_df=data_df.withColumn(\"weights\",substring(\"weight\",1,3))\n",
        "data_df=data_df.drop(\"weight\")\n",
        "data_df = data_df.withColumn(\"heights\",fn.round((regexp_extract('height','(\\d)..(\\d)',1)*30.48+regexp_extract('height','(\\d)..(\\d)',2)*2.54),2))\n",
        "data_df = data_df.drop(\"height\")\n",
        "\n",
        "# change datatype\n",
        "data_df=data_df.withColumn(\"age\",data_df[\"age\"].cast(types.IntegerType()))\n",
        "data_df=data_df.withColumn(\"rating\",data_df[\"rating\"].cast(types.IntegerType()))\n",
        "data_df=data_df.withColumn(\"size\",data_df[\"size\"].cast(types.DoubleType()))\n",
        "data_df=data_df.withColumn(\"weights\",data_df[\"weights\"].cast(types.DoubleType()))\n",
        "data_df=data_df.withColumn(\"heights\",data_df[\"heights\"].cast(types.DoubleType()))\n",
        "data_df=data_df.drop(\"review_date\",\"_corrupt_record\",\"item_id\",\"user_id\")\n",
        "\n",
        "# rename column\n",
        "data_df=data_df.withColumnRenamed(\"body type\",\"body_type\")\n",
        "data_df=data_df.withColumnRenamed(\"bust size\",\"bust_size\")\n",
        "data_df=data_df.withColumnRenamed(\"rented for\",\"rented_for\")\n",
        "\n",
        "# remove unusual value\n",
        "data_df=data_df.filter(data_df.age<100)\n",
        "data_df=data_df.filter(data_df.age>12)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YUNqK-f3h-Ma"
      },
      "source": [
        "# check missing values\n",
        "data_df.select([count(when(col(c).isNull(), c)).alias(c) for c in data_df.columns]).show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ifOMTHFxhc61"
      },
      "source": [
        "# remove records with missing values in rating, review_text and review_summary\n",
        "data_df = data_df.where(col('rating').isNotNull())\n",
        "data_df = data_df.where(col('review_text').isNotNull())\n",
        "data_df = data_df.where(col('review_summary').isNotNull())\n",
        "\n",
        "# subsititude null value in size, weights and heights with average values\n",
        "ave_weight = round(data_df.groupBy().avg('weights').head()[0],3)\n",
        "ave_height = round(data_df.groupBy().avg('heights').head()[0],3)\n",
        "ave_size = round(data_df.groupBy().avg('size').head()[0],0)\n",
        "\n",
        "data_df = data_df.fillna(ave_weight,subset = 'weights')\n",
        "data_df = data_df.fillna(ave_height, subset = 'heights')\n",
        "data_df = data_df.fillna(ave_size, subset = 'size')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oOR4I8FniLmk"
      },
      "source": [
        "# check the most common bust_size\n",
        "data_df.orderBy(\"bust_size\", ascending = False).take(1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1RE28t5KiPpO"
      },
      "source": [
        "# check the most common bust_size\n",
        "data_df.orderBy(\"bust_size\", ascending = False).take(1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iHlnKcTJiQQ_"
      },
      "source": [
        "# fill null values in body_type, bust_size and rented_for with the most common value\n",
        "data_df = data_df.fillna('hourglass',subset = 'body_type')\n",
        "data_df = data_df.fillna('44f',subset = 'bust_size')\n",
        "data_df = data_df.fillna('work',subset = 'rented_for')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fed6eIu8lVRI"
      },
      "source": [
        "# check missing values again\n",
        "data_df.select([count(when(col(c).isNull(), c)).alias(c) for c in data_df.columns]).show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "title": "",
          "showTitle": false,
          "inputWidgets": {},
          "nuid": "f5a2782d-5360-4b1e-b11d-07ab42baf8bd"
        },
        "id": "ehayJBf4APUN"
      },
      "source": [
        "# compute total count for body_type and rating \n",
        "body_type_df1=data_df.groupBy(data_df.body_type).count().toPandas()\n",
        "rating_df1=data_df.groupBy(data_df.rating).count().toPandas()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "title": "",
          "showTitle": false,
          "inputWidgets": {},
          "nuid": "24d0b319-8549-4abe-9065-9dae1dd2bf21"
        },
        "id": "oPKBEmHkAPUR"
      },
      "source": [
        "# define function to draw bar plot\n",
        "def draw_bar(dataframe,column):\n",
        "    plt.figure()\n",
        "    p1 = dataframe.plot(kind='bar', x=column, width =1,fontsize = 8, edgecolor='black')\n",
        "    p1.set_xlabel('%s '%column)\n",
        "    p1.set_ylabel('count')\n",
        "    plt.xticks(rotation=45)\n",
        "    p1.set_title('Total count for %s'%column)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "title": "",
          "showTitle": false,
          "inputWidgets": {},
          "nuid": "bedf0b3b-95fd-411e-a342-f1aaf65d3b4c"
        },
        "id": "m854HfOVAPUU"
      },
      "source": [
        "# bar plot \n",
        "draw_bar(body_type_df1,\"body_type\")\n",
        "draw_bar(rating_df1,\"rating\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zpm6tCksSMYM"
      },
      "source": [
        "# data exploration\n",
        "draw_bar(data_df.groupby(data_df.fit).count().toPandas(),'fit')\n",
        "draw_bar(data_df.groupby(data_df.body_type).count().toPandas(),'body_type')\n",
        "draw_bar(data_df.groupby(data_df.rented_for).count().toPandas(),'rented_for')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BVM6-k1G2_QP"
      },
      "source": [
        "# top 10 category\n",
        "category_count = data_df.groupby(data_df.category).count().sort('count',ascending = False).toPandas()[:10]\n",
        "plt.figure()\n",
        "p1 = category_count.plot(kind='bar', x='category', width =1,fontsize = 8, edgecolor='black')\n",
        "p1.set_xlabel('category')\n",
        "p1.set_ylabel('count')\n",
        "plt.xticks(rotation=45)\n",
        "p1.set_title('Total count for top ten category')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W1obb3kqbCaA"
      },
      "source": [
        "# data exploration of 'age'\n",
        "var = 'age'\n",
        "x = data_df.select(var).toPandas()[var]\n",
        "bins = np.arange(0, 100, 5.0)\n",
        "hist, bin_edges = np.histogram(x,bins,weights=np.zeros_like(x) + 100. / x.size)\n",
        "# make the histogram\n",
        "\n",
        "fig = plt.figure(figsize=(20, 8))\n",
        "ax = fig.add_subplot(1, 2, 1)\n",
        "\n",
        "# Plot the histogram heights against integers on the x axis\n",
        "ax.bar(range(len(hist)),hist,width=1,alpha=0.8,ec ='black', color='gold')\n",
        "# # Set the ticks to the middle of the bars\n",
        "ax.set_xticks([0.5+i for i,j in enumerate(hist)])\n",
        "# Set the xticklabels to a string that tells us what the bin edges were\n",
        "labels =['{}'.format(int(bins[i+1])) for i,j in enumerate(hist)]\n",
        "labels.insert(0,'0')\n",
        "ax.set_xticklabels(labels)\n",
        "plt.xlabel(var)\n",
        "plt.ylabel('percentage')\n",
        "plt.title('Age Distribution')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ylwjr0jnl4lz"
      },
      "source": [
        "# Part 2: Sentiment Analysis"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8GaOij8il-x1"
      },
      "source": [
        "## prediction 1\n",
        "# reformat weight and height \n",
        "\n",
        "# set rating that lower than or equal 5 to logical value 0, rating that greater than 5 to logical value 1\n",
        "data_df_senti = data_df.withColumn('attitude', when(data_df['rating'] > 5, 1).otherwise(0))\n",
        "\n",
        "training_df, validation_df, testing_df = data_df_senti.randomSplit([0.6, 0.3, 0.1], seed=0)\n",
        "\n",
        "# tokenize function\n",
        "tokenizer = RegexTokenizer().setGaps(False).setPattern(\"\\\\p{L}+\").setInputCol(\"review_text\").setOutputCol(\"words\")\n",
        "\n",
        "# remove stop words function\n",
        "stop_words = requests.get('http://ir.dcs.gla.ac.uk/resources/linguistic_utils/stop_words').text.split()\n",
        "stop_words_remover = StopWordsRemover().setStopWords(stop_words).setCaseSensitive(False).setInputCol(\"words\").setOutputCol(\"words_cleaned\")\n",
        "\n",
        "# create a countvectorizer transformer\n",
        "cv = CountVectorizer(minTF=1., minDF=5., vocabSize=2**17).setInputCol(\"words_cleaned\").setOutputCol(\"tf\")\n",
        "\n",
        "# TF-IDF function\n",
        "idf = IDF(inputCol=\"tf\", outputCol=\"tf_idf\")\n",
        "\n",
        "\n",
        "# create a pipeline to tokenize, remove stop words, and do a TF-IDF transformation.\n",
        "pipe_senti_1 = Pipeline(stages = [tokenizer, stop_words_remover, cv, idf])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sLXIg6_hn8Rn"
      },
      "source": [
        "# import original logistic regression model\n",
        "lr = LogisticRegression().setLabelCol(\"attitude\").setFeaturesCol(\"tf_idf\")\n",
        "lr_pipe = Pipeline(stages = [pipe_senti_1, lr])\n",
        "lr_fit = lr_pipe.fit(training_df)\n",
        "\n",
        "pipeline_model_1 = pipe_senti_1.fit(training_df)\n",
        "\n",
        "# Score the original model using ROC AUC\n",
        "evaluator = evaluation.BinaryClassificationEvaluator(labelCol = \"attitude\")\n",
        "lr_auc = evaluator.evaluate(lr_fit.transform(testing_df)) \n",
        "print(\"the resulting AUC is\", lr_auc, \"!!!\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_nsxBrPv7nqe"
      },
      "source": [
        "# set enable_grid to True or False\n",
        "enable_grid = True"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P2fAbhpSp0ph"
      },
      "source": [
        "# improve the model\n",
        "from pyspark.ml.tuning import ParamGridBuilder\n",
        "\n",
        "# find the best model\n",
        "if enable_grid:\n",
        "    # grid search code\n",
        "    lr_pipe_1 = lr_pipe\n",
        "    grid = ParamGridBuilder().addGrid(lr.regParam, [0., 0.01, 0.02]).addGrid(lr.elasticNetParam, [0., 0.2, 0.4]).build()\n",
        "    all_models = []\n",
        "    for j in range(len(grid)):\n",
        "        print(\"Fitting model {}\".format(j+1))\n",
        "        model = lr_pipe_1.fit(training_df, grid[j])\n",
        "        all_models.append(model)\n",
        "    # estimate the accuracy of each of them:\n",
        "    accuracies = [m.\\\n",
        "        transform(validation_df).\\\n",
        "        select(fn.avg(fn.expr('float(attitude = prediction)')).alias('accuracy')).\\\n",
        "        first().\\\n",
        "        accuracy for m in all_models]\n",
        "\n",
        "    best_model_idx = np.argmax(accuracies)\n",
        "    print(\"best model index =\", best_model_idx)\n",
        "\n",
        "    print(grid[best_model_idx])\n",
        "    best_model = all_models[best_model_idx]\n",
        "    best_model.\\\n",
        "        transform(testing_df).\\\n",
        "        select(fn.avg(fn.expr('float(attitude = prediction)')).alias('accuracy')).\\\n",
        "        show() \n",
        "    pass"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1_2_6O-ZqOvG"
      },
      "source": [
        "# compare the score of best model with the original one\n",
        "lambda_par = 0.01\n",
        "alpha_par = 0.2\n",
        "\n",
        "lr_2 = LogisticRegression().\\\n",
        "        setLabelCol('attitude').\\\n",
        "        setFeaturesCol('tf_idf').\\\n",
        "        setRegParam(lambda_par).\\\n",
        "        setMaxIter(100).\\\n",
        "        setElasticNetParam(alpha_par)\n",
        "\n",
        "lr_pipe_2 = Pipeline(stages = [pipe_senti_1, lr_2])\n",
        "lr_pipe_2_fit = lr_pipe_2.fit(training_df)\n",
        "lr_2_auc = evaluator.evaluate(lr_pipe_2_fit.transform(testing_df))\n",
        "\n",
        "compare_df = pd.DataFrame({\"model_name\" : [\"lr_pipe\", \"lr_pipe_2\"], \"auc_score\" : [lr_auc, lr_2_auc]})\n",
        "\n",
        "display(compare_df)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "48Uw0lIVqSBr"
      },
      "source": [
        "score_2 = lr_pipe_2_fit.stages[-1].coefficients.toArray()\n",
        "vocab_list_2 = lr_pipe_2_fit.stages[0].stages[-2].vocabulary\n",
        "lr_pipe_df_2 = pd.DataFrame({\"word\" : vocab_list_2, \"score\" : score_2})\n",
        "\n",
        "# The 10 most negative words are:\n",
        "lr_pipe_df_neg_1  = lr_pipe_df_2.sort_values(by = \"score\")[:10].reset_index(drop = True)\n",
        "# The 10 most positive words are:\n",
        "lr_pipe_df_pos_1 = lr_pipe_df_2.sort_values(by = \"score\", ascending = False)[:10].reset_index(drop = True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4SrPLvSDqYYa"
      },
      "source": [
        "# The 10 most negative words:\n",
        "display(lr_pipe_df_neg_1)\n",
        "# The 10 most positive words:\n",
        "display(lr_pipe_df_pos_1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1LR1CosuqZnu"
      },
      "source": [
        "# ROC curve\n",
        "ROC_df = lr_pipe_2_fit.stages[-1].summary.roc.select(\"FPR\",\"TPR\").toPandas()\n",
        "\n",
        "plt.plot([0, 1], [0, 1], \"r--\", label = \"Random\")\n",
        "plt.plot(ROC_df.FPR, ROC_df.TPR, label = \"ROC Curve\")\n",
        "plt.xlabel(\"False Positive Rate\")\n",
        "plt.ylabel(\"True Positive Rate\")\n",
        "plt.title(\"ROC Curve of The Best Model\")\n",
        "plt.legend(loc = \"lower right\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Dvwl7tyqcNk"
      },
      "source": [
        "# PR curve\n",
        "PR_df = lr_pipe_2_fit.stages[-1].summary.pr.select(\"Recall\", \"Precision\").toPandas()\n",
        "\n",
        "plt.plot(PR_df.Recall, PR_df.Precision, label = \"PR Curve\")\n",
        "plt.xlabel(\"Recall\")\n",
        "plt.ylabel(\"Precision\")\n",
        "plt.title(\"PR Curve of The Best Model\")\n",
        "plt.legend(loc = \"lower left\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_7NoZ2QFkrta"
      },
      "source": [
        "# Part 3: Products with High Rating Analysis"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wN0LriXL3eHx"
      },
      "source": [
        "## prediction 2\n",
        "# remove irrelevent columns\n",
        "df2=data_df.drop(\"review_summary\",\"review_text\")\n",
        "\n",
        "# define function to extract distinct value of each column as a list\n",
        "def extract_list(columnname):\n",
        "  temp=df2.select(columnname).distinct().collect()\n",
        "  temp=[str(row[0])for row in temp]\n",
        "  return temp\n",
        "body_type=extract_list(\"body_type\")\n",
        "bust_size=extract_list(\"bust_size\")\n",
        "category=extract_list(\"category\")\n",
        "fit=extract_list(\"fit\")\n",
        "rented_for=extract_list(\"rented_for\")\n",
        "\n",
        "# reformat rating column\n",
        "df2=df2.withColumn(\"new_rating\",when(col('rating')< 6, \"low\").when(col('rating')==6,\"medium\").otherwise('high')).drop('rating')\n",
        "rating=df2.select(\"new_rating\").distinct().collect()\n",
        "rating=[str(row[0])for row in rating]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yyi-APibadFc"
      },
      "source": [
        "print(rating)\n",
        "print(fit)\n",
        "print(body_type)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F81Vh6n13wJh"
      },
      "source": [
        "# build a pipeline\n",
        "feature_pipe1=Pipeline(stages=[feature.StringIndexerModel.from_labels(body_type, inputCol=\"body_type\",outputCol=\"body_id\"),\n",
        "                              feature.StringIndexerModel.from_labels(fit, inputCol=\"fit\",outputCol=\"fit_id\"),\n",
        "                              feature.StringIndexerModel.from_labels(rating, inputCol=\"new_rating\",outputCol=\"new_rating_id\"),\n",
        "                              feature.StringIndexerModel.from_labels(rented_for, inputCol=\"rented_for\",outputCol=\"rented_id\"),\n",
        "                              feature.VectorAssembler(inputCols=['age', 'body_id','fit_id', 'rented_id','weights','heights'], outputCol='total_features')\n",
        "                      ])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lIOlW_V_CPZC"
      },
      "source": [
        "# fit and transform\n",
        "df2_featured=feature_pipe1.fit(df2).transform(df2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GX4IFFKoXWau"
      },
      "source": [
        "# split into training, test and validation dataset\n",
        "(trainingData,testData,validationData) = df2_featured.randomSplit([0.6,0.3,0.1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OCWqWEn-Jo6j"
      },
      "source": [
        "# tune parameters and find the maximum F-measure score\n",
        "rf=RandomForestClassifier(labelCol=\"new_rating_id\",featuresCol=\"total_features\")\n",
        "paramGrid = ParamGridBuilder().addGrid(rf.numTrees, [6,7,8]).addGrid(rf.maxDepth, [5,6,7]).build()\n",
        "all_models = []\n",
        "rf_evaluator = mce(labelCol=\"new_rating_id\", predictionCol=\"prediction\",metricName=\"f1\")\n",
        "all_f=[]\n",
        "for j in range(len(paramGrid)):\n",
        "  rf_model = rf.fit(trainingData, paramGrid[j])\n",
        "  all_models.append(rf_model)\n",
        "  f1 = rf_evaluator.evaluate(rf_model.transform(validationData))\n",
        "  all_f.append(f1)\n",
        "best_model_idx = all_f.index(max(all_f))\n",
        "best_model = all_models[best_model_idx]\n",
        "print(\"The maximum F-measure score is \",max(all_f))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xtK2HQ-gvKq8"
      },
      "source": [
        "# use the parameter set above train and test data\n",
        "max_depth=best_model.getOrDefault('maxDepth')\n",
        "numtrees=best_model.getOrDefault('numTrees')\n",
        "best_rf=RandomForestClassifier(labelCol=\"new_rating_id\",featuresCol=\"total_features\",maxDepth=max_depth,numTrees=numtrees)\n",
        "best_rf_model=best_rf.fit(trainingData)\n",
        "rf_evaluator.evaluate(best_rf_model.transform(testData))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kk0pjQ_JhfMi"
      },
      "source": [
        "# print the tree structure\n",
        "print(best_rf_model.toDebugString)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nc-6d4txc0JS"
      },
      "source": [
        "# extract feature\n",
        "features = []\n",
        "for i in range(6):\n",
        "  features.append(best_rf_model.featureImportances[i])\n",
        "imp_feature = pd.DataFrame({'features':['age', 'body_type','fit', 'rented_for','weights','heights'],\\\n",
        "                            'importances':features})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uDSGpxqVcB6W"
      },
      "source": [
        "# feature importance plot \n",
        "ax=imp_feature.plot(x='features',kind='barh',title='Feature Importance')\n",
        "ax.set_xlabel(\"Importance_score\")\n",
        "ax.set_ylabel(\"Feature_name\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kuGVwVI3lAKy"
      },
      "source": [
        "# Part 4: Recommendation Analysis"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4VpXtofh603v"
      },
      "source": [
        "## prediction 3\n",
        "# extract useful columns from main dataframe\n",
        "df4=data_df.where(col('fit')== 'fit').where(col('rating')==10)\n",
        "df4=df4.select(concat_ws('_',df4.body_type,df4.bust_size,df4.category).alias('full'),'review_summary')\n",
        "df4=df4.select('*',lower(col('review_summary'))).drop('review_summary').select(col('lower(review_summary)').alias('review_summary'),col('full'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Te9YgRlIycYP"
      },
      "source": [
        "# create a pipeline including tokenization, stopwordsfilter, TF-IDF, standardscaler and PCA\n",
        "quotes_tokenizer = RegexTokenizer(minTokenLength=2).setGaps(False).setPattern(\"\\\\p{L}+\").setInputCol(\"review_summary\").setOutputCol(\"words\")\n",
        "#stop words\n",
        "stop_words = requests.get('http://ir.dcs.gla.ac.uk/resources/linguistic_utils/stop_words').text.split()\n",
        "stopwords_filter = StopWordsRemover().setStopWords(stop_words).setCaseSensitive(False).setInputCol(\"words\").setOutputCol(\"filtered\")\n",
        "#TF\n",
        "cv = CountVectorizer(minDF=5.).setInputCol(\"filtered\").setOutputCol(\"tf\")\n",
        "#IDF\n",
        "idf = IDF().setInputCol('tf').setOutputCol('tfidf')\n",
        "pipe_pca_1=Pipeline(stages=[quotes_tokenizer,stopwords_filter,cv,idf,feature.StandardScaler(withMean=True,withStd=False,inputCol='tfidf',outputCol='centered_tfidf'),feature.PCA(k=2, inputCol='centered_tfidf', outputCol='scores')]).fit(df4)\n",
        "chars_pca_df=pipe_pca_1.transform(df4)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lA_dUkOb4CHd"
      },
      "source": [
        "# show the result \n",
        "chars_pca_df.show(10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FcSLuxMf42Dx"
      },
      "source": [
        "# define function to compute distance \n",
        "def l2_dist(c1, c2):    \n",
        "    return float(np.sqrt((c1 - c2).T.dot((c1 - c2))))\n",
        "l2_dist_udf = fn.udf(l2_dist, types.FloatType())\n",
        "spark.sql(\"SET spark.sql.crossJoin.enabled=TRUE\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sq50Ap-ZK9mA"
      },
      "source": [
        "# train a k-means model.\n",
        "evaluator = ClusteringEvaluator().setFeaturesCol(\"scores\").setPredictionCol(\"prediction\").setMetricName(\"silhouette\")\n",
        "scores=[]\n",
        "k=[]\n",
        "for i in range(2,4):\n",
        "  k.append(i)\n",
        "  kmeans = KMeans().setK(i).setFeaturesCol(\"scores\").setPredictionCol(\"prediction\")\n",
        "  model = kmeans.fit(chars_pca_df)\n",
        "# Make predictions\n",
        "  predictions = model.transform(chars_pca_df)\n",
        "# Evaluate clustering by computing Silhouette score\n",
        "  score=evaluator.evaluate(predictions)\n",
        "  scores.append(score)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LgLV8_5q1pSm"
      },
      "source": [
        "# plot the data\n",
        "plt.figure()\n",
        "plt.plot(k, scores)\n",
        "plt.title(\"silhouette score vs K\")\n",
        "plt.xlabel(\"K\")\n",
        "plt.ylabel(\"silhouette score\")\n",
        "print('The highest silhouette score is',max(scores),'and its K is',k[scores.index(max(scores))])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XkOPUXbB3A41"
      },
      "source": [
        "# perform K-Means clustering using k=3\n",
        "kmeans = KMeans().setK(3).setFeaturesCol(\"scores\").setPredictionCol(\"prediction\")\n",
        "model = kmeans.fit(chars_pca_df)\n",
        "predictions = model.transform(chars_pca_df)\n",
        "PCAscores = np.array(predictions.select('scores').rdd.map(lambda x: x['scores']).collect())\n",
        "loadings = pipe_pca_1.stages[-1].pc.toArray()\n",
        "k_list=predictions.select('prediction').collect()\n",
        "k_list=[int(row.prediction)for row in k_list]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SU1eIbSi3T7a"
      },
      "source": [
        "# plot the cluster result\n",
        "xs = PCAscores[:,0]\n",
        "ys = PCAscores[:,1]\n",
        "n = loadings.shape[0]\n",
        "scalex = 1.0/(xs.max() - xs.min())\n",
        "scaley = 1.0/(ys.max() - ys.min())\n",
        "    \n",
        "x = xs * scalex\n",
        "y = ys * scaley\n",
        "fig,ax = plt.subplots()\n",
        "sc = plt.scatter(x, y,c=k_list)\n",
        "legend1 = ax.legend(*sc.legend_elements(),\n",
        "                  loc=\"lower right\", title=\"Classes\")\n",
        "ax.add_artist(legend1)\n",
        "plt.xlim(-1,1)\n",
        "plt.ylim(-1,1)\n",
        "plt.xlabel(\"PC{}\".format(1))\n",
        "plt.ylabel(\"PC{}\".format(2))\n",
        "plt.title(\"cluster result\")\n",
        "plt.grid()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hJA29_QHCxnI"
      },
      "source": [
        "# create three different clusters\n",
        "cluster_0=predictions.select('full','prediction').where(col('prediction')==0).groupBy('full').count().sort('count',ascending=False)\n",
        "cluster_1=predictions.select('full','prediction').where(col('prediction')==1).groupBy('full').count().sort('count',ascending=False)\n",
        "cluster_2=predictions.select('full','prediction').where(col('prediction')==2).groupBy('full').count().sort('count',ascending=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zotab3W4Yce_"
      },
      "source": [
        "# the result of previous action\n",
        "cluster_0.show(10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p0UIkJjxbMG1"
      },
      "source": [
        "# extract several examples from clusters\n",
        "cluster_0_pd=cluster_0.toPandas().rename(columns={'full':'cluster0'}).iloc[[1,3,4],]\n",
        "cluster_1_pd=cluster_1.toPandas().rename(columns={'full':'cluster1'}).head(3)\n",
        "cluster_2_pd=cluster_2.toPandas().rename(columns={'full':'cluster2'}).iloc[[7,8,18],]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OF2AY6uKcw2f"
      },
      "source": [
        "# show the result of previous action\n",
        "display(cluster_0_pd)\n",
        "display(cluster_1_pd)\n",
        "display(cluster_2_pd)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yjs3yzTJiH7U"
      },
      "source": [
        "# plot top 3 for cluster0\n",
        "plt.figure()\n",
        "p0=cluster_0_pd.plot.bar( x='cluster0',y='count',rot=0,color='purple')\n",
        "p0.set_xlabel('cluster0')\n",
        "p0.set_ylabel('count')\n",
        "plt.xticks(rotation=0)\n",
        "p0.set_title('Top three for cluster0')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nJb10qbyfmqt"
      },
      "source": [
        "# plot top 3 for cluster1\n",
        "plt.figure()\n",
        "p1=cluster_1_pd.plot.bar( x='cluster1',y='count',rot=0,color='green')\n",
        "p1.set_xlabel('cluster1')\n",
        "p1.set_ylabel('count')\n",
        "plt.xticks(rotation=0)\n",
        "p1.set_title('Top three for cluster1')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GYQ_TdgfioDd"
      },
      "source": [
        "# plot top 3 for cluster2\n",
        "plt.figure()\n",
        "p2=cluster_2_pd.plot.bar( x='cluster2',y='count',rot=0,color='gold')\n",
        "p2.set_xlabel('cluster2')\n",
        "p2.set_ylabel('count')\n",
        "plt.xticks(rotation=0)\n",
        "p2.set_title('Top three for cluster2')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WHEMDOHblflf"
      },
      "source": [
        "# Part 5: Customer Rating Preference Analysis\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XIHydHQ6IN1z"
      },
      "source": [
        "# prediction 4\n",
        "df3 = data_df.drop('review_summary', 'review_text')\n",
        "# high rating means rating is 10\n",
        "df3 = df3.withColumn('rating_high', when(data_df.rating == 10, 1).otherwise(0))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cAjpYyYcRdnp"
      },
      "source": [
        "# create features pipeline to transform categorical variables into numerical values\n",
        "feature_trans = Pipeline(\n",
        "    stages = [StringIndexer(inputCol=\"body_type\", outputCol=\"body_type_Num\"),\\\n",
        "              StringIndexer(inputCol=\"bust_size\", outputCol=\"bust_size_Num\"),\\\n",
        "              StringIndexer(inputCol=\"category\", outputCol=\"category_Num\"),\\\n",
        "              StringIndexer(inputCol=\"rented_for\", outputCol=\"rented_for_Num\"),\\\n",
        "              OneHotEncoder(inputCol=\"body_type_Num\", outputCol=\"body_type_Vector\"),\\\n",
        "              OneHotEncoder(inputCol=\"bust_size_Num\", outputCol=\"bust_size_Vector\"),\\\n",
        "              OneHotEncoder(inputCol=\"category_Num\", outputCol=\"category_Vector\"),\\\n",
        "              OneHotEncoder(inputCol=\"rented_for_Num\", outputCol=\"rented_for_Vector\")])\n",
        "\n",
        "# transform original dataframe\n",
        "transformed_df3 = feature_trans.fit(df3).transform(df3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J7EVUUTkd2Bj"
      },
      "source": [
        "body_type_list = sorted(set([(i[1], i[0]) for i in transformed_df3.\\\n",
        "                             select(transformed_df3.body_type,\\\n",
        "                                    transformed_df3.body_type_Num).collect()]),\\\n",
        "                        key=lambda x: x[0])\n",
        "bust_size_list = sorted(set([(i[1], i[0]) for i in transformed_df3.\\\n",
        "                             select(transformed_df3.bust_size,\\\n",
        "                                    transformed_df3.bust_size_Num).collect()]),\\\n",
        "                        key=lambda x: x[0])\n",
        "category_list = sorted(set([(i[1], i[0]) for i in transformed_df3.\\\n",
        "                             select(transformed_df3.category,\\\n",
        "                                    transformed_df3.category_Num).collect()]),\\\n",
        "                        key=lambda x: x[0])\n",
        "rented_for_list = sorted(set([(i[1], i[0]) for i in transformed_df3.\\\n",
        "                             select(transformed_df3.rented_for,\\\n",
        "                                    transformed_df3.rented_for_Num).collect()]),\\\n",
        "                        key=lambda x: x[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p9ZEMvd0_BSU"
      },
      "source": [
        "# split training and testing data\n",
        "transformed_df3 = transformed_df3.drop('body_type_Num','bust_size_Num','category_Num','rented_for_Num')\n",
        "train_dt,test_dt = transformed_df3.randomSplit([0.8,0.2],seed=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uDVRJHy5RfQM"
      },
      "source": [
        "\n",
        "\n",
        "*   **Decision Tree**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5z09RjR4uwgF"
      },
      "source": [
        "# create pipeline\n",
        "va = VectorAssembler(inputCols = ['body_type_Vector',\\\n",
        "                                  'category_Vector','rented_for_Vector',\\\n",
        "                                  'size','age'],\\\n",
        "                     outputCol='features')\n",
        "sd = StandardScaler(withMean=True, inputCol='features', outputCol='centered_features')\n",
        "\n",
        "dt = DecisionTreeClassifier(maxDepth=5, labelCol=\"rating_high\", featuresCol=\"centered_features\")\n",
        "\n",
        "ppl_cv = Pipeline(stages = [va,sd,dt])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T6fZWrb_17Pc"
      },
      "source": [
        "# cross validation for decision tree\n",
        "paramGrid = ParamGridBuilder() \\\n",
        "      .addGrid(dt.maxDepth, [4, 5, 6]) \\\n",
        "      .build()\n",
        "evaluator = bce(labelCol=\"rating_high\", rawPredictionCol=\"prediction\",metricName= \"areaUnderROC\")\n",
        "\n",
        "crossval = CrossValidator(estimator = ppl_cv,\\\n",
        "                            estimatorParamMaps=paramGrid,\\\n",
        "                            evaluator = evaluator,\\\n",
        "                            numFolds= 5)\n",
        "\n",
        "cv_model = crossval.fit(train_dt)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D7LK9lGA88mC"
      },
      "source": [
        "# transform testing data\n",
        "dt_model = cv_model.bestModel\n",
        "dt_MaxDepth = dt_model.stages[-1].getMaxDepth()\n",
        "print(\"The max depth of decision tree is\", dt_MaxDepth)\n",
        "dt_predictions = dt_model.transform(test_dt)\n",
        "dt_accuracy = evaluator.evaluate(dt_predictions)\n",
        "print(\"The AUC of decision tree is\", dt_accuracy)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F86feOvTR-aY"
      },
      "source": [
        "\n",
        "\n",
        "*   **Logistic Regression**\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MAGSdhvMEFib"
      },
      "source": [
        "# create pipeline\n",
        "css = ChiSqSelector(featuresCol='centered_features',outputCol='Aspect',labelCol='rating_high',fpr=0.05)\n",
        "lr = LogisticRegression().\\\n",
        "    setLabelCol('rating_high').\\\n",
        "    setFeaturesCol('Aspect').\\\n",
        "    setRegParam(0.0).\\\n",
        "    setMaxIter(100).\\\n",
        "    setElasticNetParam(0.)\n",
        "\n",
        "lr_estimator = Pipeline(stages = [va,sd,css,lr])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PXQ18rhdHPij"
      },
      "source": [
        "# cross validation of logistic regression\n",
        "lr_grid = ParamGridBuilder().\\\n",
        "            addGrid(lr.regParam, [0.005, 0.01]).\\\n",
        "            addGrid(lr.elasticNetParam, [0.01,0.05]).\\\n",
        "            build()\n",
        "\n",
        "lr_cv = CrossValidator(estimator = lr_estimator,\\\n",
        "                            estimatorParamMaps=lr_grid,\\\n",
        "                            evaluator = evaluator,\\\n",
        "                            numFolds= 3)\n",
        "\n",
        "lr_cv_model = lr_cv.fit(train_dt)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WPIcRQngvmUv"
      },
      "source": [
        "# best model with parameters and transform testing data\n",
        "lr_model = lr_cv_model.bestModel\n",
        "reg_lambda = lr_model.stages[-1].getRegParam()\n",
        "net_alpha = lr_model.stages[-1].getElasticNetParam()\n",
        "print(\"The best lambda is\",reg_lambda,\"and the best alpha is\", net_alpha)\n",
        "\n",
        "lr_predictions = lr_model.transform(test_dt)\n",
        "lr_accuracy = evaluator.evaluate(lr_predictions)\n",
        "print(\"The AUC of logistic regression is\", lr_accuracy)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tbuyYGseS3Ae"
      },
      "source": [
        "\n",
        "\n",
        "*   **Gradient-boosted Tree**\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X0mOohr-6hCg"
      },
      "source": [
        "# create pipeline\n",
        "gbt = GBTClassifier(labelCol=\"rating_high\", featuresCol=\"centered_features\", maxIter=10)\n",
        "gbt_estimator = Pipeline(stages=[va,sd,gbt])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "os98OdNc8PvN"
      },
      "source": [
        "# cross validation of gradient-boosted tree\n",
        "gbt_grid = ParamGridBuilder().\\\n",
        "          addGrid(gbt.maxDepth, [4, 5, 6]).\\\n",
        "          build()\n",
        "\n",
        "gbt_cv = CrossValidator(estimator = gbt_estimator,\\\n",
        "                        estimatorParamMaps=gbt_grid,\\\n",
        "                        evaluator = evaluator,\\\n",
        "                        numFolds= 5)\n",
        "\n",
        "gbt_cv_model = gbt_cv.fit(train_dt)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7zw1EYc79M_9"
      },
      "source": [
        "gbt_model = gbt_cv_model.bestModel\n",
        "gbt_MaxDepth = gbt_model.stages[-1].getMaxDepth()\n",
        "print(\"The max depth of gradient-boost tree is {}.\".format(gbt_MaxDepth))\n",
        "gbt_predictions = gbt_model.transform(test_dt)\n",
        "gbt_accuracy = evaluator.evaluate(gbt_predictions)\n",
        "print(\"The AUC of gradient-boost tree is\", gbt_accuracy)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jpFFupHnT8RQ"
      },
      "source": [
        "\n",
        "\n",
        "*   **Model Comparison**\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NP_N3NmlBSUL"
      },
      "source": [
        "# draw ROC curve\n",
        "from pyspark.mllib.evaluation import BinaryClassificationMetrics as bcm\n",
        "from sklearn.metrics import roc_curve, auc\n",
        "\n",
        "preds = dt_predictions.select('rating_high','probability').rdd.map(lambda row: (float(row['probability'][1]), float(row['rating_high']))).collect()\n",
        "preds1 = lr_predictions.select('rating_high','probability').rdd.map(lambda row: (float(row['probability'][1]), float(row['rating_high']))).collect()\n",
        "preds2 = gbt_predictions.select('rating_high','probability').rdd.map(lambda row: (float(row['probability'][1]), float(row['rating_high']))).collect()\n",
        "\n",
        "fpr = dict()\n",
        "tpr = dict()\n",
        "fpr1 = dict()\n",
        "tpr1 = dict()\n",
        "fpr2 = dict()\n",
        "tpr2 = dict()\n",
        "\n",
        "y_pre = [i[1] for i in preds]\n",
        "y_pro = [i[0] for i in preds]\n",
        "y_pre1 = [i[1] for i in preds1]\n",
        "y_pro1 = [i[0] for i in preds1]\n",
        "y_pre2 = [i[1] for i in preds2]\n",
        "y_pro2 = [i[0] for i in preds2]\n",
        "\n",
        "fpr, tpr, _ = roc_curve(y_pre, y_pro)\n",
        "fpr1, tpr1, _1 = roc_curve(y_pre1, y_pro1)\n",
        "fpr2, tpr2, _2 = roc_curve(y_pre2, y_pro2)\n",
        "\n",
        "plt.figure()\n",
        "plt.plot(fpr, tpr,label='Decision Tree')\n",
        "plt.plot(fpr1,tpr1,label='Logistic Regression')\n",
        "plt.plot(fpr2,tpr2,label='Gradient-boosted Tree')\n",
        "\n",
        "plt.xlabel('FPR')\n",
        "plt.ylabel('TPR')\n",
        "plt.title('ROC curve')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MCwJtX73EoFJ"
      },
      "source": [
        "# draw Precision/Recall curve\n",
        "from sklearn.metrics import precision_recall_curve as prc\n",
        "precision, recall, _ = prc(y_pre, y_pro)\n",
        "precision1, recall1, _1 = prc(y_pre1, y_pro1)\n",
        "precision2, recall2, _2 = prc(y_pre2, y_pro2)\n",
        "\n",
        "plt.figure()\n",
        "plt.plot(recall, precision,label= 'Decision Tree')\n",
        "plt.plot(recall1, precision1, label= 'Logistic Regression')\n",
        "plt.plot(recall2, precision2, label= 'Gradient-boosted Tree')\n",
        "\n",
        "plt.xlabel('Recall')\n",
        "plt.ylabel('Precision')\n",
        "plt.title('Precision/Recall curve')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z18SSDOnmGZy"
      },
      "source": [
        "# table of AUC of each model\n",
        "compare_df = pd.DataFrame({'Model':['DT', 'LR', 'GBT'],'AUC':[dt_accuracy,lr_accuracy,gbt_accuracy]})\n",
        "compare_df = compare_df.sort_values('AUC',ascending=False)\n",
        "display(compare_df)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tYZU79ApUBzQ"
      },
      "source": [
        "\n",
        "\n",
        "*   **Important Features of Best Model**\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hLpgUIr7KTUn"
      },
      "source": [
        "# select most important 10 features\n",
        "feature_weights = pd.DataFrame({'index':gbt_model.stages[-1].featureImportances.indices,\\\n",
        "                               'weights':gbt_model.stages[-1].featureImportances.values})\n",
        "feature_weights = feature_weights.sort_values('weights',ascending=False)[:10]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FJpa_ygNsDEK"
      },
      "source": [
        "# create data frame of important features\n",
        "imp_feature = pd.DataFrame({'features':['size','party: cocktail','gown',\\\n",
        "                      'petite','date','sheath','pear',\\\n",
        "                      'everyday','work','apple'],\\\n",
        "               'importance':feature_weights['weights']}).\\\n",
        "        sort_values('importance',ascending=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dq_QrPuJ5sCX"
      },
      "source": [
        "# important feature visualization\n",
        "fi = imp_feature.plot(x='features',kind='barh',title='Feature Importance')\n",
        "fi.set_xlabel('importance score')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GanL6rbfyHiR"
      },
      "source": [
        "# the structure of gradient-boosted tree\n",
        "tree = gbt_model.stages[-1]\n",
        "tree.toDebugString"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}